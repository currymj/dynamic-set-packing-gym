{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import gym_dynamic_set_packing\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch distributions experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.tensor(np.ones((2,16), dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Either `probs` or `logits` must be specified, but not both.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-f7d32479924c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Either `probs` or `logits` must be specified, but not both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Either `probs` or `logits` must be specified, but not both."
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(16, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32,2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = torch.distributions.Categorical(net(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1060, -0.1060], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.log_prob(dist.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training loop code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomMatchAgent:\n",
    "    \"A simple agent for the 0/1 problem that always matches.\"\n",
    "    def __init__(self, match_prob):\n",
    "        self.policy_dist = torch.distributions.Categorical(torch.tensor([match_prob, 1 - match_prob], dtype=torch.float32))\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "\n",
    "    def act(self, observation, reward, done):\n",
    "        action_sample = self.policy_dist.sample()\n",
    "        return action_sample.item()\n",
    "    \n",
    "    def learn(self, history_dict):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(env, agent, episode_count, max_steps, quiet=False):\n",
    "    done = False\n",
    "    ep_rewards = []\n",
    "    for i in tqdm(range(episode_count)):\n",
    "        reward = 0.0\n",
    "        if not quiet:\n",
    "            print('episode {}'.format(i))\n",
    "        ob = env.reset()\n",
    "        total_reward = 0.0\n",
    "        history_dict = {\n",
    "            'actions': [],\n",
    "            'observations': [],\n",
    "            'rewards': []\n",
    "        }\n",
    "        for i in range(max_steps):\n",
    "            history_dict['observations'].append(ob)\n",
    "            action = agent.act(ob, reward, done)\n",
    "            history_dict['actions'].append(action)\n",
    "            ob, reward, done, _ = env.step(action)\n",
    "            history_dict['rewards'].append(reward)\n",
    "            total_reward += reward\n",
    "            if not quiet:\n",
    "                print('action taken: {}, reward: {}, new state: {}'.format(action, reward, env.render()))\n",
    "        agent.learn(history_dict)\n",
    "        history_dict = None\n",
    "        if not quiet:\n",
    "            print('total episode reward: {}'.format(total_reward))\n",
    "        ep_rewards.append(total_reward)\n",
    "    return ep_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(env_example.reset(),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discounted_episode_returns(rewards, gamma=0.99):\n",
    "    \"\"\"\n",
    "    Given a sequence of rewards, returns the sequence\n",
    "    of the discounted returns (G_t) at each time step,\n",
    "    with discount rate gamma (default 0.999).\n",
    "    \"\"\"\n",
    "    # thanks to yuhao for writing this code for another project\n",
    "    length = len(rewards)\n",
    "    discounts = [gamma**x for x in range(length)]\n",
    "    result = [np.dot(discounts[:length-i], rewards[i:]) for i in range(length)]\n",
    "    return np.array(result, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pg_target(policy_dist, rewards, action_trajectory):\n",
    "    \"\"\"\n",
    "    The policy gradient target loss (without baseline). Note it has to be negative,\n",
    "    because TF optimizers only want to minimize. Rewards should be cumulative and discounted.\n",
    "    All inputs should already be TensorFlow objects, not lists or np arrays.\n",
    "    \"\"\"\n",
    "    return -torch.mean(policy_dist.log_prob(action_trajectory)*rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPMatchAgent:\n",
    "    def __init__(self, observation_shape, gamma=0.99):\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        \n",
    "        self.policy_net = nn.Sequential(\n",
    "            nn.Linear(observation_shape, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,2)\n",
    "        )\n",
    "        self.optimizer = torch.optim.Adam(self.policy_net.parameters())\n",
    "        self.gamma = gamma\n",
    "        ## need to compile for non-eager mode?\n",
    "    \n",
    "    def policy(self, observation_batch):\n",
    "        return torch.distributions.Categorical(logits=self.policy_net(observation_batch))\n",
    "    \n",
    "    def act(self, observation, reward, done):\n",
    "        \"Act on a single observation, return an action.\"\n",
    "        observation_as_batch = torch.tensor(np.expand_dims(observation, 0), dtype=torch.float32, requires_grad=False)\n",
    "        action_sample = self.policy(observation_as_batch).sample().detach().numpy()\n",
    "        return action_sample[0]\n",
    "    \n",
    "    def learn(self, history_dict):\n",
    "        \"Perform the policy gradient update with its optimizer and policy.\"\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        obs_tensor = torch.tensor(history_dict['observations'], dtype=torch.float32, requires_grad=False)\n",
    "        returns_tensor = torch.tensor(discounted_episode_returns(history_dict['rewards'], gamma=self.gamma), dtype=torch.float32, requires_grad=False)\n",
    "        actions_tensor = torch.tensor(history_dict['actions'], dtype=torch.float32, requires_grad=False)\n",
    "        policy_dists = self.policy(obs_tensor)\n",
    "        loss = pg_target(policy_dists,\n",
    "                             returns_tensor,\n",
    "                             actions_tensor)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag = MLPMatchAgent(16)\n",
    "ag.act(env_example.reset(), 1.0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mlp example (not sure if training totally correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed55e979bfd94cff965f01b2301dda51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "env_example = gym.make('DynamicSetPacking-silly-v0')\n",
    "ag = MLPMatchAgent(env_example.observation_space.shape[0], gamma=0.999)\n",
    "ep_rewards = train_loop(env_example, ag, 10, 10, quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## blood types example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c1737d0148407bbc13a59b03e23ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "env_example = gym.make('DynamicSetPacking-gurobitest-v0')\n",
    "ag = MLPMatchAgent(env_example.observation_space.shape[0], gamma=0.999)\n",
    "ep_rewards = train_loop(env_example, ag, 1000, 50, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb40e7e3668>]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ep_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare to random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomMatchAgent:\n",
    "    \"A simple agent for the 0/1 problem that always matches.\"\n",
    "    def __init__(self, match_prob):\n",
    "        self.policy_dist = tfd.OneHotCategorical(probs=[1.0-match_prob, match_prob])\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "\n",
    "    def act(self, observation, reward, done):\n",
    "        action_sample = self.policy_dist.sample()\n",
    "        return action_sample.numpy()\n",
    "    \n",
    "    def learn(self, history_dict):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b775c0b7831943b58b128ca7bc458e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/curry/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_probability/python/distributions/onehot_categorical.py:172: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n",
      "Academic license - for non-commercial use only\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5215d084af27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menv_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DynamicSetPacking-gurobitest-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomMatchAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrandom_ep_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-2bce025b4022>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(env, agent, episode_count, max_steps, quiet)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_onehot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# save the onehot version for logprob later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rewards'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/dynamic-set-packing-gym/gym_dynamic_set_packing/envs/dynamic_set_packing_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mchosen_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_perform_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_match\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/dynamic-set-packing-gym/gym_dynamic_set_packing/envs/dynamic_set_packing_env.py\u001b[0m in \u001b[0;36m_perform_match\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_perform_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/dynamic-set-packing-gym/gym_dynamic_set_packing/matchers/matcher.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mrow_sums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinExpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_vars\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_sum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_sums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddConstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_sum\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetObjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquicksum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_sums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAXIMIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env_example = gym.make('DynamicSetPacking-gurobitest-v0')\n",
    "ag = RandomMatchAgent(0.5)\n",
    "random_ep_rewards = train_loop(env_example, ag, 300, 50, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(random_ep_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_silly_env(agent, episode_count, max_steps):\n",
    "    env = gym.make('DynamicSetPacking-silly-v0')\n",
    "    reward = 0.0\n",
    "    done = False\n",
    "    for i in range(episode_count):\n",
    "        print('episode {}'.format(i))\n",
    "        ob = env.reset()\n",
    "        total_reward = 0.0\n",
    "        history_dict = {\n",
    "            'actions': [],\n",
    "            'observations': [],\n",
    "            'rewards': []\n",
    "        }\n",
    "        for i in range(max_steps):\n",
    "            history_dict['observations'].append(ob)\n",
    "            \n",
    "            action_onehot = agent.act(ob, reward, done)\n",
    "            history_dict['actions'].append(action_onehot) # save the onehot version for logprob later\n",
    "            action = np.argmax(action_onehot)\n",
    "            ob, reward, done, _ = env.step(action)\n",
    "            history_dict['rewards'].append(reward)\n",
    "            total_reward += reward\n",
    "            print('action taken: {}, reward: {}, new state: {}'.format(action, reward, env.render()))\n",
    "        agent.learn(history_dict)\n",
    "        print('total episode reward: {}'.format(total_reward))\n",
    "def test_silly_env(agent, episode_count, max_steps):\n",
    "    env = gym.make('DynamicSetPacking-silly-v0')\n",
    "    reward = 0.0\n",
    "    done = False\n",
    "    for i in range(episode_count):\n",
    "        print('episode {}'.format(i))\n",
    "        ob = env.reset()\n",
    "        total_reward = 0.0\n",
    "        history_dict = {\n",
    "            'actions': [],\n",
    "            'observations': [],\n",
    "            'rewards': []\n",
    "        }\n",
    "        for i in range(max_steps):\n",
    "            history_dict['observations'].append(ob)\n",
    "            \n",
    "            action_onehot = agent.act(ob, reward, done)\n",
    "            history_dict['actions'].append(action_onehot) # save the onehot version for logprob later\n",
    "            action = np.argmax(action_onehot)\n",
    "            ob, reward, done, _ = env.step(action)\n",
    "            history_dict['rewards'].append(reward)\n",
    "            total_reward += reward\n",
    "            print('action taken: {}, reward: {}, new state: {}'.format(action, reward, env.render()))\n",
    "        print('total episode reward: {}'.format(total_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old pg update func, saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pg_update(history_dict, policy_model, optim):\n",
    "    \"\"\"Attempt at making a policy gradient update. Seems to be working.\n",
    "    \n",
    "    policy_model should output a TFP dist so we can get the log_prob.\n",
    "    optim is any TensorFlow optimizer (Adam tends to work)\n",
    "    history_dict should contain 'observations', 'rewards', and 'actions' from a rollout.\n",
    "    \"\"\"\n",
    "    # policy_model outputs a TFP distribution\n",
    "    # here, starting to define policy gradient operations. use gradient tape\n",
    "    with tf.GradientTape() as tape:\n",
    "        policy_dists = policy_model(tf.constant(history_dict['observations']))\n",
    "        loss = pg_target(policy_dists, tf.constant(history_dict['rewards']), tf.constant(history_dict['actions']))\n",
    "    gradients = tape.gradient(loss, policy_model.trainable_variables)\n",
    "    optim.apply_gradients(zip(gradients, policy_model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random agent example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomMatchAgent:\n",
    "    \"A simple agent for the 0/1 problem that always matches.\"\n",
    "    def __init__(self, match_prob):\n",
    "        self.policy_dist = tfd.OneHotCategorical(probs=[1.0-match_prob, match_prob])\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "\n",
    "    def act(self, observation, reward, done):\n",
    "        action_sample = self.policy_dist.sample()\n",
    "        return action_sample.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_silly_env(RandomMatchAgent(0.3), 1, 10)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "10d8b0a12de7412e90d33db5c825912f",
   "lastKernelId": "5cca33df-2b73-48fc-a5c8-c2dbcfa6bd82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
